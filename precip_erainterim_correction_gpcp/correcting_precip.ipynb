{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A method to correct precipitation fields for ocean models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*R. Dussin*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regridding GPCP v2.3 to ERAinterim grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to regrid the satelite-based precipitations onto the Atmospheric reanalyse grid. This can be done easily with xesmf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcpdir = './'\n",
    "gpcp = xr.open_dataset(gpcpdir + 'precip.mon.mean.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp['precip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xesmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erai_dir = '/archive/Raphael.Dussin/ERAinterim/nc_daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erai_grid = xr.open_dataset(f'{erai_dir}/precip_ERAinterim_1979_daily.nc', decode_times=False, drop_variables=['time', 'precip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erai_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the cell edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA-interim\n",
    "\n",
    "lon = erai_grid['lon'].values\n",
    "lon_bnds = np.concatenate((np.array([lon[0] -0.5 * 0.7031]), 0.5 * (lon[:-1] + lon[1:]), np.array([lon[-1] + 0.5 * 0.7031])), axis=0)\n",
    "\n",
    "lat = erai_grid['lat'].values\n",
    "lat_bnds = np.concatenate((np.array([-90]), 0.5 * (lat[:-1] + lat[1:]), np.array([90])), axis=0)\n",
    "\n",
    "erai_grid['lon_b'] = xr.DataArray(data=lon_bnds, dims=('lonp1'))\n",
    "erai_grid['lat_b'] = xr.DataArray(data=lat_bnds, dims=('latp1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPCP\n",
    "\n",
    "gpcp['lon_b'] = xr.DataArray(data=np.arange(0,360+2.5,2.5), dims=('lonp1'))\n",
    "gpcp['lat_b'] = xr.DataArray(data=np.arange(-90,90+2.5,2.5), dims=('latp1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp2erai = xesmf.Regridder(gpcp, erai_grid, 'conservative', periodic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp_precip_interp = gpcp2erai(gpcp['precip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp_precip_interp.sel(time='2016-1').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp_regridded = xr.Dataset()\n",
    "gpcp_regridded['precip'] = gpcp_precip_interp\n",
    "gpcp_regridded.to_netcdf('./GPCP_v2.3_256x512.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumul_precip(da):\n",
    "    ''' apply cumsum and scale data array'''\n",
    "    # create cumulated precip\n",
    "    da_cs = da.cumsum(dim='time')\n",
    "    # concat with zero initial value, needed for decumul\n",
    "    zeroslice = xr.zeros_like(da_cs.isel(time=0))\n",
    "    da_cs = xr.concat([zeroslice, da_cs], dim='time')\n",
    "    return da_cs\n",
    "\n",
    "def normalize_cumulated_precip(da):\n",
    "    # normalize to the last value\n",
    "    norm = da.isel(time=-1).clip(min=1e-15)\n",
    "    da_scaled = da / norm\n",
    "    return da_scaled\n",
    "\n",
    "def decumul_precip(da):\n",
    "    out = da.diff('time')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* extract monthly data from ERAinterim yearly file\n",
    "* cumul/scale the data and reserve\n",
    "* conservative regridding of monthly GPCP onto ERAinterim grid\n",
    "* total precip in GPCP = avg monthly value * ndays_in_month\n",
    "* rescale the cumulative sum with GPCP value (smoothing required?)\n",
    "* run decumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_year(ds_erai, da_gpcp):\n",
    "    current_year = ds_erai.time.dt.year[0].values\n",
    "    print(current_year)\n",
    "    ds_out = xr.zeros_like(ds_erai)\n",
    "    for month in range(12):\n",
    "        cmonth = str(month+1).zfill(2)\n",
    "        data_month = ds_erai['rain'].sel(time=f'{current_year}-{cmonth}')\n",
    "        ndays = len(data_month.time)\n",
    "        #print(data_month.time)\n",
    "        cumul = cumul_precip(data_month.clip(min=0))\n",
    "        cumul_normed = normalize_cumulated_precip(cumul)\n",
    "        new_total = da_gpcp.sel(time=f'{current_year}-{cmonth}').values.squeeze()\n",
    "        new_total = new_total * ndays / 1000  # total precip in meters\n",
    "        ny, nx = new_total.shape\n",
    "        new_data_month = decumul_precip(cumul_normed.transpose(*('time', 'lat', 'lon')) * new_total) * 1000 / 86400 # kg.m-2.s-1\n",
    "        if month == 0:\n",
    "            da_out = new_data_month.copy()\n",
    "        else:\n",
    "            da_out = xr.concat([da_out, new_data_month], dim='time')\n",
    "    ds_out['rain'] = da_out\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '/archive/Raphael.Dussin/ERAinterim/blend_GPCP'\n",
    "encoding = {'time': {'_FillValue': 0}, 'lon': {'_FillValue': 1e+36},\n",
    "            'lat': {'_FillValue': 1e+36}, 'rain': {'_FillValue': 1e+36}}\n",
    "\n",
    "for year in np.arange(1979,2018+1):\n",
    "    precip = xr.open_dataset(f'{erai_dir}/precip_ERAinterim_{year}_daily.nc')\n",
    "    snow = xr.open_dataset(f'{erai_dir}/snow_ERAinterim_{year}_daily.nc')\n",
    "    rain = (precip['precip'] - snow[\"snow\"]).clip(min=0).to_dataset(name='rain')\n",
    "    ds_time = xr.open_dataset(f'{erai_dir}/precip_ERAinterim_{year}_daily.nc', decode_times=False)\n",
    "    ds_corrected = process_one_year(rain, gpcp_precip_interp)\n",
    "    ds_corrected['time'] = ds_time['time']\n",
    "    ds_corrected['rain'].attrs = {'valid_min': 0., 'valid_max': 1e-2}\n",
    "    ds_corrected.to_netcdf(f'{outdir}/rain_Dussin_corrected_{year}_daily.nc', encoding=encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-repro4",
   "language": "python",
   "name": "repro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
