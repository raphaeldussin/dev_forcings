{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A method to correct precipitation fields for ocean models: sensitivity to degraded GPCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*R. Dussin*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regridding GPCP v2.3 to ERAinterim grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to regrid the satelite-based precipitations onto the Atmospheric reanalyse grid. This can be done easily with xesmf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcpdir = './'\n",
    "gpcp = xr.open_dataset(gpcpdir + 'precip.mon.mean.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp['precip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xesmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erai_dir = '/archive/Raphael.Dussin/ERAinterim/nc_daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erai_grid = xr.open_dataset(f'{erai_dir}/precip_ERAinterim_1979_daily.nc', decode_times=False, drop_variables=['time', 'precip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erai_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the cell edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA-interim\n",
    "\n",
    "lon = erai_grid['lon'].values\n",
    "lon_bnds = np.concatenate((np.array([lon[0] -0.5 * 0.7031]), 0.5 * (lon[:-1] + lon[1:]), np.array([lon[-1] + 0.5 * 0.7031])), axis=0)\n",
    "\n",
    "lat = erai_grid['lat'].values\n",
    "lat_bnds = np.concatenate((np.array([-90]), 0.5 * (lat[:-1] + lat[1:]), np.array([90])), axis=0)\n",
    "\n",
    "erai_grid['lon_b'] = xr.DataArray(data=lon_bnds, dims=('lonp1'))\n",
    "erai_grid['lat_b'] = xr.DataArray(data=lat_bnds, dims=('latp1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPCP\n",
    "\n",
    "gpcp['lon_b'] = xr.DataArray(data=np.arange(0,360+2.5,2.5), dims=('lonp1'))\n",
    "gpcp['lat_b'] = xr.DataArray(data=np.arange(-90,90+2.5,2.5), dims=('latp1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp2erai = xesmf.Regridder(gpcp, erai_grid, 'conservative', periodic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp_precip_interp = gpcp2erai(gpcp['precip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp_precip_interp.sel(time='2016-1').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output= False\n",
    "if write_output:\n",
    "    gpcp_regridded = xr.Dataset()\n",
    "    gpcp_regridded['precip'] = gpcp_precip_interp\n",
    "    gpcp_regridded.to_netcdf('./GPCP_v2.3_256x512.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Degrade GPCP to annual and 5x5 degree (sensitivity tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_by_ndays(da):\n",
    "    month_weights = []\n",
    "    for year in list(set(da['time'].dt.year.values)):\n",
    "        ndays_year = 366 if calendar.isleap(year) else 365\n",
    "        for month in range(1, 13):\n",
    "            _, ndays = calendar.monthrange(year, month)\n",
    "            month_weights.append(float(ndays)/ndays_year)\n",
    "    xr_wgts = xr.DataArray(month_weights, dims=('time'), coords={'time': da['time']})\n",
    "    return xr_wgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = weight_by_ndays(gpcp['precip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check (all weights should sum to one for each year)\n",
    "wgts.groupby(wgts.time.dt.year).sum(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPCP_annual = (gpcp['precip'] * wgts).groupby(gpcp['time'].dt.year).sum(dim='time').rename({'year': 'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPCP_annual.sel(time=2006).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPCP_annual_interp = gpcp2erai(GPCP_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPCP_annual_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_regular_grid(lon, lat, Rearth=6378e3, hres=2.5):\n",
    "    \"\"\" compute the cells area on a regular grid \"\"\"\n",
    "\n",
    "    rfac = 2 * np.pi * Rearth / 360\n",
    "    dx1d = rfac * hres\n",
    "    dy1d = rfac * hres\n",
    "\n",
    "    dx2d, dy2d = np.meshgrid(dx1d, dy1d)\n",
    "    _, lat2d = np.meshgrid(lon, lat)\n",
    "\n",
    "    dx = dx2d * np.cos(2 * np.pi * lat2d / 360)\n",
    "    dy = dy2d\n",
    "    area = dx * dy\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_gpcp = area_regular_grid(gpcp[\"lon\"], gpcp[\"lat\"], Rearth=6378e3, hres=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: global sum adds up to expected value with 0.01% relative tolerance\n",
    "assert np.allclose(area_gpcp.sum(), 4*np.pi*6378e3*6378e3, rtol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp[\"area\"] = xr.DataArray(area_gpcp, dims=('lat', 'lon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp_precip_coarsened = (gpcp[\"precip\"] * gpcp[\"area\"]).coarsen(lon=2, lat=2).sum() / gpcp[\"area\"].coarsen(lon=2, lat=2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp_5x = gpcp_precip_coarsened.to_dataset(name='precip')\n",
    "gpcp_5x['lon_b'] = xr.DataArray(data=np.arange(0,360+5,5), dims=('lonp1'))\n",
    "gpcp_5x['lat_b'] = xr.DataArray(data=np.arange(-90,90+5,5), dims=('latp1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp_5x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual check on degraded and original resolution\n",
    "gpcp_5x[\"precip\"].sel(time='2016-1').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp[\"precip\"].sel(time='2016-1').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remap the degraded GPCP to the ERAinterim grid as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp_5x_2erai = xesmf.Regridder(gpcp_5x, erai_grid, 'conservative', periodic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp5x_precip_interp = gpcp_5x_2erai(gpcp_5x['precip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcp5x_precip_interp.sel(time='2016-1').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output= True\n",
    "if write_output:\n",
    "    gpcp5x_regridded = xr.Dataset()\n",
    "    gpcp5x_regridded['precip'] = gpcp5x_precip_interp\n",
    "    gpcp5x_regridded.to_netcdf('./GPCP_v2.3_5x5deg_256x512.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumul_precip(da):\n",
    "    ''' apply cumsum and scale data array'''\n",
    "    # create cumulated precip\n",
    "    da_cs = da.cumsum(dim='time')\n",
    "    # concat with zero initial value, needed for decumul\n",
    "    zeroslice = xr.zeros_like(da_cs.isel(time=0))\n",
    "    da_cs = xr.concat([zeroslice, da_cs], dim='time')\n",
    "    return da_cs\n",
    "\n",
    "def normalize_cumulated_precip(da):\n",
    "    # normalize to the last value\n",
    "    norm = da.isel(time=-1).clip(min=1e-15)\n",
    "    da_scaled = da / norm\n",
    "    return da_scaled\n",
    "\n",
    "def decumul_precip(da):\n",
    "    out = da.diff('time')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* extract monthly data from ERAinterim yearly file\n",
    "* cumul/scale the data and reserve\n",
    "* conservative regridding of monthly GPCP onto ERAinterim grid\n",
    "* total precip in GPCP = avg monthly value * ndays_in_month\n",
    "* rescale the cumulative sum with GPCP value (smoothing required?)\n",
    "* run decumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_year(ds_erai, da_gpcp):\n",
    "    current_year = ds_erai.time.dt.year[0].values\n",
    "    print(current_year)\n",
    "    ds_out = xr.zeros_like(ds_erai)\n",
    "    for month in range(12):\n",
    "        cmonth = str(month+1).zfill(2)\n",
    "        data_month = ds_erai['precip'].sel(time=f'{current_year}-{cmonth}')\n",
    "        ndays = len(data_month.time)\n",
    "        #print(data_month.time)\n",
    "        cumul = cumul_precip(data_month.clip(min=0))\n",
    "        cumul_normed = normalize_cumulated_precip(cumul)\n",
    "        new_total = da_gpcp.sel(time=f'{current_year}-{cmonth}').values.squeeze()\n",
    "        new_total = new_total * ndays / 1000  # total precip in meters\n",
    "        ny, nx = new_total.shape\n",
    "        new_data_month = decumul_precip(cumul_normed.transpose(*('time', 'lat', 'lon')) * new_total) * 1000 / 86400 # kg.m-2.s-1\n",
    "        if month == 0:\n",
    "            da_out = new_data_month.copy()\n",
    "        else:\n",
    "            da_out = xr.concat([da_out, new_data_month], dim='time')\n",
    "    ds_out['precip'] = da_out\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivy computations (annual GPCP and GPCP 5x5 degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5x5 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '/archive/Raphael.Dussin/ERAinterim/blend_GPCP_v2_sens_5x'\n",
    "encoding = {'time': {'_FillValue': 0}, 'lon': {'_FillValue': 1e+36},\n",
    "            'lat': {'_FillValue': 1e+36}, 'rain': {'_FillValue': 1e+36}}\n",
    "\n",
    "encoding2 = {'time': {'_FillValue': 0}, 'lon': {'_FillValue': 1e+36},\n",
    "            'lat': {'_FillValue': 1e+36}, 'precip': {'_FillValue': 1e+36}}\n",
    "\n",
    "for year in np.arange(1979,2018+1):\n",
    "    precip = xr.open_dataset(f'{erai_dir}/precip_ERAinterim_{year}_daily.nc')\n",
    "    snow = xr.open_dataset(f'{erai_dir}/snow_ERAinterim_{year}_daily.nc')\n",
    "    precip_corrected = process_one_year(precip, gpcp5x_precip_interp)\n",
    "    # remove snow from ERAinterim to get corrected rainfall\n",
    "    rain_corrected = (precip_corrected['precip'] - snow[\"snow\"]).clip(min=0).to_dataset(name='rain')\n",
    "    ds_time = xr.open_dataset(f'{erai_dir}/precip_ERAinterim_{year}_daily.nc', decode_times=False)\n",
    "    precip_corrected['time'] = ds_time['time']\n",
    "    precip_corrected[\"precip\"].attrs = {'valid_min': 0., 'valid_max': 1e-2}\n",
    "    precip_corrected.to_netcdf(f'{outdir}/precip_Dussin_corrected_{year}_daily_GPCP5X.nc',\n",
    "                               format='NETCDF3_64BIT', encoding=encoding2)\n",
    "    \n",
    "    rain_corrected['time'] = ds_time['time']\n",
    "    rain_corrected['rain'].attrs = {'valid_min': 0., 'valid_max': 1e-2}\n",
    "    rain_corrected.to_netcdf(f'{outdir}/rain_Dussin_corrected_{year}_daily_GPCP5X.nc',\n",
    "                             format='NETCDF3_64BIT', encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual GPCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_year_from_annual(ds_erai, da_gpcp):\n",
    "    current_year = ds_erai.time.dt.year[0].values\n",
    "    print(current_year)\n",
    "    ds_out = xr.zeros_like(ds_erai)\n",
    "    # cumul all year\n",
    "    cumul = cumul_precip(ds_erai[\"precip\"].clip(min=0))\n",
    "    cumul_normed = normalize_cumulated_precip(cumul)\n",
    "    new_total = da_gpcp.sel(time=current_year).values.squeeze()\n",
    "    ndays = 366 if calendar.isleap(current_year) else 365\n",
    "    new_total = new_total * ndays / 1000\n",
    "    ny, nx = new_total.shape\n",
    "    new_data = decumul_precip(cumul_normed.transpose(*('time', 'lat', 'lon')) * new_total) * 1000 / 86400 # kg.m-2.s-1\n",
    "    ds_out['precip'] = new_data\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '/archive/Raphael.Dussin/ERAinterim/blend_GPCP_v2_sens_1y'\n",
    "encoding = {'time': {'_FillValue': 0}, 'lon': {'_FillValue': 1e+36},\n",
    "            'lat': {'_FillValue': 1e+36}, 'rain': {'_FillValue': 1e+36}}\n",
    "\n",
    "encoding2 = {'time': {'_FillValue': 0}, 'lon': {'_FillValue': 1e+36},\n",
    "            'lat': {'_FillValue': 1e+36}, 'precip': {'_FillValue': 1e+36}}\n",
    "\n",
    "for year in np.arange(1979,2018+1):\n",
    "    precip = xr.open_dataset(f'{erai_dir}/precip_ERAinterim_{year}_daily.nc')\n",
    "    snow = xr.open_dataset(f'{erai_dir}/snow_ERAinterim_{year}_daily.nc')\n",
    "    precip_corrected = process_one_year_from_annual(precip, GPCP_annual_interp)\n",
    "    # remove snow from ERAinterim to get corrected rainfall\n",
    "    rain_corrected = (precip_corrected['precip'] - snow[\"snow\"]).clip(min=0).to_dataset(name='rain')\n",
    "    ds_time = xr.open_dataset(f'{erai_dir}/precip_ERAinterim_{year}_daily.nc', decode_times=False)\n",
    "    precip_corrected['time'] = ds_time['time']\n",
    "    precip_corrected[\"precip\"].attrs = {'valid_min': 0., 'valid_max': 1e-2}\n",
    "    precip_corrected.to_netcdf(f'{outdir}/precip_Dussin_corrected_{year}_daily_GPCP1Y.nc',\n",
    "                               format='NETCDF3_64BIT', encoding=encoding2)\n",
    "    rain_corrected['time'] = ds_time['time']\n",
    "    rain_corrected['rain'].attrs = {'valid_min': 0., 'valid_max': 1e-2}\n",
    "    rain_corrected.to_netcdf(f'{outdir}/rain_Dussin_corrected_{year}_daily_GPCP1Y.nc',\n",
    "                             format='NETCDF3_64BIT', encoding=encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-repro4",
   "language": "python",
   "name": "repro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
